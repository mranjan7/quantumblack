{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quantumblack_71_4.ipynb', 'quantumblack (3).ipynb', 'quantumblack (5).ipynb', 'saved_files', 'quantumblack.ipynb', 'quantumblack_71_3.ipynb', 'quantumblack_71_current.ipynb', 'all_data.pkl', 'quantumblack_71-Copy2.ipynb', 'engine_features.csv', 'quantumblack_71-5.ipynb', 'weather_features.csv', 'quantumblack_71-mean.ipynb', 'data', '.ipynb_checkpoints', 'drive_features.csv', 'quantumblack_71_current-Copy1.ipynb', 'quantumblack_71.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\".\"))\n",
    "\n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "from haversine import haversine\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from numba import njit\n",
    "import pygeohash as pgh\n",
    "from sklearn import preprocessing\n",
    "from dateutil import tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data and some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"./data/\"\n",
    "sub_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('saved_files'):\n",
    "    os.makedirs('saved_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(input_path,filename):\n",
    "    df = None\n",
    "    try:\n",
    "        saved_file = 'saved_files/'+filename+'.pkl'\n",
    "        df = pd.read_pickle(saved_file)\n",
    "    except Exception as e:\n",
    "        print('Exception ',e,'Could not load ','saved_files/'+filename+'.pkl',' making it now')\n",
    "        df = pd.read_csv(input_path+filename+'.csv')\n",
    "    with open('saved_files/'+filename+'.pkl',mode='wb') as saved_file:\n",
    "        pickle.dump(df,saved_file)\n",
    "    return df\n",
    "\n",
    "def load_folder(input_path,folder_name):\n",
    "    df = None\n",
    "    try:\n",
    "        saved_file = 'saved_files/'+folder_name+'.pkl'\n",
    "        df = pd.read_pickle(saved_file)\n",
    "    except Exception as e:\n",
    "        print('Exception ',e,'Could not load ','saved_files/'+folder_name+'.pkl',' making it now')\n",
    "        df = None\n",
    "        for file in os.listdir(input_path + folder_name):\n",
    "            if file.endswith('.parquet'):\n",
    "                temp = pd.read_parquet(input_path + folder_name+'/'+str(file),engine ='pyarrow')\n",
    "                if df is None:\n",
    "                    df = temp\n",
    "                else:\n",
    "                    df = pd.concat([df,temp])\n",
    "                    \n",
    "    with open('saved_files/'+folder_name+'.pkl',mode='wb') as saved_file:\n",
    "        pickle.dump(df,saved_file)\n",
    "    return df\n",
    "\n",
    "def downcast_dtypes(df):\n",
    "    int_cols = [c for c in df if df[c].dtype == 'int64']\n",
    "    float_cols = [c for c in df if df[c].dtype == 'float64']\n",
    "    df[int_cols] = df[int_cols].astype(np.int32)\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    return df\n",
    "\n",
    "def round_floats(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == 'float64']\n",
    "    df[float_cols] = df[float_cols].round(0).astype(np.int32)\n",
    "    float_cols = [c for c in df if df[c].dtype == 'float32']\n",
    "    df[float_cols] = df[float_cols].round(0).astype(np.int32)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_file(sub_path,'drive_features')\n",
    "ef = load_file(sub_path,'engine_features')\n",
    "wf = load_file(sub_path,'weather_features')\n",
    "vehicle_df = load_file(input_path,'vehicle')\n",
    "drive_df = load_folder(input_path,'drive')\n",
    "trip_df = load_folder(input_path,'trip')\n",
    "weather_df = load_folder(input_path,'weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>Model</th>\n",
       "      <th>drivetrain</th>\n",
       "      <th>max_torque</th>\n",
       "      <th>max_horsepower</th>\n",
       "      <th>max_horsepower_rpm</th>\n",
       "      <th>max_torque_rpm</th>\n",
       "      <th>engine_displacement</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>fuel_tank_capacity</th>\n",
       "      <th>fuel_economy_city</th>\n",
       "      <th>fuel_economy_highway</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>forced_induction</th>\n",
       "      <th>device_generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000500</td>\n",
       "      <td>2016</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Civic</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>140</td>\n",
       "      <td>6500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1.799</td>\n",
       "      <td>1059</td>\n",
       "      <td>47</td>\n",
       "      <td>16.50</td>\n",
       "      <td>20.00</td>\n",
       "      <td>4</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000501</td>\n",
       "      <td>2016</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Compass</td>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "      <td>171</td>\n",
       "      <td>3750</td>\n",
       "      <td>1250</td>\n",
       "      <td>1.956</td>\n",
       "      <td>1059</td>\n",
       "      <td>60</td>\n",
       "      <td>17.10</td>\n",
       "      <td>21.20</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000502</td>\n",
       "      <td>2016</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Creta</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>126</td>\n",
       "      <td>4000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1059</td>\n",
       "      <td>55</td>\n",
       "      <td>19.67</td>\n",
       "      <td>24.10</td>\n",
       "      <td>4</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000503</td>\n",
       "      <td>2016</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>Superb</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "      <td>177</td>\n",
       "      <td>5100</td>\n",
       "      <td>1750</td>\n",
       "      <td>1.798</td>\n",
       "      <td>1059</td>\n",
       "      <td>66</td>\n",
       "      <td>14.67</td>\n",
       "      <td>23.30</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000504</td>\n",
       "      <td>2017</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>4</td>\n",
       "      <td>350</td>\n",
       "      <td>174</td>\n",
       "      <td>3600</td>\n",
       "      <td>1500</td>\n",
       "      <td>1.968</td>\n",
       "      <td>1059</td>\n",
       "      <td>66</td>\n",
       "      <td>17.42</td>\n",
       "      <td>20.43</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000506</td>\n",
       "      <td>2017</td>\n",
       "      <td>BMW</td>\n",
       "      <td>3 Series GT</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>188</td>\n",
       "      <td>4000</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.995</td>\n",
       "      <td>1059</td>\n",
       "      <td>57</td>\n",
       "      <td>21.76</td>\n",
       "      <td>26.32</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000507</td>\n",
       "      <td>2017</td>\n",
       "      <td>Audi</td>\n",
       "      <td>Q3</td>\n",
       "      <td>3</td>\n",
       "      <td>250</td>\n",
       "      <td>148</td>\n",
       "      <td>5000</td>\n",
       "      <td>1400</td>\n",
       "      <td>1.395</td>\n",
       "      <td>1059</td>\n",
       "      <td>64</td>\n",
       "      <td>16.90</td>\n",
       "      <td>21.40</td>\n",
       "      <td>3</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vehicle_id  year        make        Model  drivetrain  max_torque  \\\n",
       "0     1000500  2016       Honda        Civic           2         174   \n",
       "1     1000501  2016        Jeep      Compass           4         350   \n",
       "2     1000502  2016     Hyundai        Creta           2         260   \n",
       "3     1000503  2016       Skoda       Superb           2         250   \n",
       "4     1000504  2017  Volkswagen       Passat           4         350   \n",
       "5     1000506  2017         BMW  3 Series GT           2         400   \n",
       "6     1000507  2017        Audi           Q3           3         250   \n",
       "\n",
       "   max_horsepower  max_horsepower_rpm  max_torque_rpm  engine_displacement  \\\n",
       "0             140                6500            1500                1.799   \n",
       "1             171                3750            1250                1.956   \n",
       "2             126                4000            1500                1.582   \n",
       "3             177                5100            1750                1.798   \n",
       "4             174                3600            1500                1.968   \n",
       "5             188                4000            1800                1.995   \n",
       "6             148                5000            1400                1.395   \n",
       "\n",
       "   fuel_type  fuel_tank_capacity  fuel_economy_city  fuel_economy_highway  \\\n",
       "0       1059                  47              16.50                 20.00   \n",
       "1       1059                  60              17.10                 21.20   \n",
       "2       1059                  55              19.67                 24.10   \n",
       "3       1059                  66              14.67                 23.30   \n",
       "4       1059                  66              17.42                 20.43   \n",
       "5       1059                  57              21.76                 26.32   \n",
       "6       1059                  64              16.90                 21.40   \n",
       "\n",
       "   cylinders  forced_induction  device_generation  \n",
       "0          4            1054.0                  5  \n",
       "1          3               NaN                  4  \n",
       "2          4            1054.0                  3  \n",
       "3          3               NaN                  2  \n",
       "4          4               NaN                  4  \n",
       "5          3               NaN                  3  \n",
       "6          3            1054.0                  2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>velocity</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "      <th>engine_coolant_temp</th>\n",
       "      <th>eng_load</th>\n",
       "      <th>fuel_level</th>\n",
       "      <th>iat</th>\n",
       "      <th>rpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000518</td>\n",
       "      <td>8e2f7799f577423c9343d1eddbbaa2b6</td>\n",
       "      <td>2017-01-06 19:00:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>45.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>92.97</td>\n",
       "      <td>177.54</td>\n",
       "      <td>205.78</td>\n",
       "      <td>142.29</td>\n",
       "      <td>143.55</td>\n",
       "      <td>2032.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000518</td>\n",
       "      <td>8e2f7799f577423c9343d1eddbbaa2b6</td>\n",
       "      <td>2017-01-06 19:00:01</td>\n",
       "      <td>70.06</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>93.82</td>\n",
       "      <td>175.88</td>\n",
       "      <td>204.11</td>\n",
       "      <td>151.80</td>\n",
       "      <td>144.89</td>\n",
       "      <td>2027.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000518</td>\n",
       "      <td>8e2f7799f577423c9343d1eddbbaa2b6</td>\n",
       "      <td>2017-01-06 19:00:02</td>\n",
       "      <td>74.38</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>85.78</td>\n",
       "      <td>170.35</td>\n",
       "      <td>202.51</td>\n",
       "      <td>143.95</td>\n",
       "      <td>148.61</td>\n",
       "      <td>2030.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000518</td>\n",
       "      <td>8e2f7799f577423c9343d1eddbbaa2b6</td>\n",
       "      <td>2017-01-06 19:00:03</td>\n",
       "      <td>71.28</td>\n",
       "      <td>54.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>93.23</td>\n",
       "      <td>161.59</td>\n",
       "      <td>197.73</td>\n",
       "      <td>142.43</td>\n",
       "      <td>140.55</td>\n",
       "      <td>2023.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000518</td>\n",
       "      <td>8e2f7799f577423c9343d1eddbbaa2b6</td>\n",
       "      <td>2017-01-06 19:00:04</td>\n",
       "      <td>77.70</td>\n",
       "      <td>52.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>93.62</td>\n",
       "      <td>161.01</td>\n",
       "      <td>201.08</td>\n",
       "      <td>135.65</td>\n",
       "      <td>142.23</td>\n",
       "      <td>2037.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vehicle_id                           trip_id            datetime  velocity  \\\n",
       "0     1000518  8e2f7799f577423c9343d1eddbbaa2b6 2017-01-06 19:00:00      0.00   \n",
       "1     1000518  8e2f7799f577423c9343d1eddbbaa2b6 2017-01-06 19:00:01     70.06   \n",
       "2     1000518  8e2f7799f577423c9343d1eddbbaa2b6 2017-01-06 19:00:02     74.38   \n",
       "3     1000518  8e2f7799f577423c9343d1eddbbaa2b6 2017-01-06 19:00:03     71.28   \n",
       "4     1000518  8e2f7799f577423c9343d1eddbbaa2b6 2017-01-06 19:00:04     77.70   \n",
       "\n",
       "   accel_x  accel_y  accel_z  engine_coolant_temp  eng_load  fuel_level  \\\n",
       "0     45.0     48.0    92.97               177.54    205.78      142.29   \n",
       "1     50.0     45.0    93.82               175.88    204.11      151.80   \n",
       "2     50.0     45.0    85.78               170.35    202.51      143.95   \n",
       "3     54.0     48.0    93.23               161.59    197.73      142.43   \n",
       "4     52.0     44.0    93.62               161.01    201.08      135.65   \n",
       "\n",
       "      iat      rpm  \n",
       "0  143.55  2032.75  \n",
       "1  144.89  2027.28  \n",
       "2  148.61  2030.11  \n",
       "3  140.55  2023.94  \n",
       "4  142.23  2037.57  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive shape : (9217528, 12)\n",
      "No. of unique trips in drive : 1708\n",
      "Minimum date :  2017-01-01 00:00:00  Maximum date :  2017-02-28 12:25:55\n"
     ]
    }
   ],
   "source": [
    "print('drive shape :',drive_df.shape)\n",
    "print('No. of unique trips in drive :',len(drive_df['trip_id'].unique()))\n",
    "print('Minimum date : ',drive_df['datetime'].min(),' Maximum date : ',drive_df['datetime'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicle_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>velocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000512</td>\n",
       "      <td>861170e5f30342c78d9b706ae908dc4f</td>\n",
       "      <td>2017-01-06 21:00:00</td>\n",
       "      <td>30.812500</td>\n",
       "      <td>-91.1875</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000512</td>\n",
       "      <td>861170e5f30342c78d9b706ae908dc4f</td>\n",
       "      <td>2017-01-06 21:00:01</td>\n",
       "      <td>30.812778</td>\n",
       "      <td>-91.1875</td>\n",
       "      <td>45.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000512</td>\n",
       "      <td>861170e5f30342c78d9b706ae908dc4f</td>\n",
       "      <td>2017-01-06 21:00:02</td>\n",
       "      <td>30.813056</td>\n",
       "      <td>-91.1875</td>\n",
       "      <td>46.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000512</td>\n",
       "      <td>861170e5f30342c78d9b706ae908dc4f</td>\n",
       "      <td>2017-01-06 21:00:03</td>\n",
       "      <td>30.813333</td>\n",
       "      <td>-91.1875</td>\n",
       "      <td>59.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000512</td>\n",
       "      <td>861170e5f30342c78d9b706ae908dc4f</td>\n",
       "      <td>2017-01-06 21:00:04</td>\n",
       "      <td>30.813611</td>\n",
       "      <td>-91.1875</td>\n",
       "      <td>52.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vehicle_id                           trip_id            datetime  \\\n",
       "0     1000512  861170e5f30342c78d9b706ae908dc4f 2017-01-06 21:00:00   \n",
       "1     1000512  861170e5f30342c78d9b706ae908dc4f 2017-01-06 21:00:01   \n",
       "2     1000512  861170e5f30342c78d9b706ae908dc4f 2017-01-06 21:00:02   \n",
       "3     1000512  861170e5f30342c78d9b706ae908dc4f 2017-01-06 21:00:03   \n",
       "4     1000512  861170e5f30342c78d9b706ae908dc4f 2017-01-06 21:00:04   \n",
       "\n",
       "         lat     long  velocity  \n",
       "0  30.812500 -91.1875      0.00  \n",
       "1  30.812778 -91.1875     45.59  \n",
       "2  30.813056 -91.1875     46.78  \n",
       "3  30.813333 -91.1875     59.48  \n",
       "4  30.813611 -91.1875     52.71  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip shape : (9217528, 6)\n",
      "No. of unique trips in trip : 1708\n",
      "Minimum date :  2017-01-01 00:00:00  Maximum date :  2017-02-28 12:25:55\n"
     ]
    }
   ],
   "source": [
    "print('trip shape :',trip_df.shape)\n",
    "print('No. of unique trips in trip :',len(trip_df['trip_id'].unique()))\n",
    "print('Minimum date : ',trip_df['datetime'].min(),' Maximum date : ',trip_df['datetime'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>temperature_data</th>\n",
       "      <th>temperature_unit</th>\n",
       "      <th>precipitation_data</th>\n",
       "      <th>precipitation_unit</th>\n",
       "      <th>wind_ew_data</th>\n",
       "      <th>wind_ew_unit</th>\n",
       "      <th>wind_ns_data</th>\n",
       "      <th>wind_ns_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258</td>\n",
       "      <td>38</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>07Z</td>\n",
       "      <td>29.8125</td>\n",
       "      <td>-92.6875</td>\n",
       "      <td>286.530000</td>\n",
       "      <td>k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>kg/m^2</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>m/s</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205</td>\n",
       "      <td>38</td>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>23Z</td>\n",
       "      <td>29.8125</td>\n",
       "      <td>-99.3125</td>\n",
       "      <td>291.740000</td>\n",
       "      <td>k</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>kg/m^2</td>\n",
       "      <td>-7.380000</td>\n",
       "      <td>m/s</td>\n",
       "      <td>7.190000</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>60</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>04Z</td>\n",
       "      <td>32.5625</td>\n",
       "      <td>-102.1875</td>\n",
       "      <td>282.400000</td>\n",
       "      <td>k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>kg/m^2</td>\n",
       "      <td>-5.980000</td>\n",
       "      <td>m/s</td>\n",
       "      <td>-2.080000</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>43</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>02Z</td>\n",
       "      <td>30.4375</td>\n",
       "      <td>-109.4375</td>\n",
       "      <td>289.970000</td>\n",
       "      <td>k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>kg/m^2</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>m/s</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211</td>\n",
       "      <td>33</td>\n",
       "      <td>2017-01-14</td>\n",
       "      <td>09Z</td>\n",
       "      <td>29.1875</td>\n",
       "      <td>-98.5625</td>\n",
       "      <td>290.530000</td>\n",
       "      <td>k</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>kg/m^2</td>\n",
       "      <td>-4.810000</td>\n",
       "      <td>m/s</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>m/s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x   y        date time      lat       lon temperature_data  \\\n",
       "0  258  38  2017-02-01  07Z  29.8125  -92.6875       286.530000   \n",
       "1  205  38  2017-01-15  23Z  29.8125  -99.3125       291.740000   \n",
       "2  182  60  2017-01-14  04Z  32.5625 -102.1875       282.400000   \n",
       "3  124  43  2017-02-28  02Z  30.4375 -109.4375       289.970000   \n",
       "4  211  33  2017-01-14  09Z  29.1875  -98.5625       290.530000   \n",
       "\n",
       "  temperature_unit precipitation_data precipitation_unit wind_ew_data  \\\n",
       "0                k           0.000000             kg/m^2     0.210000   \n",
       "1                k           0.034400             kg/m^2    -7.380000   \n",
       "2                k           0.000000             kg/m^2    -5.980000   \n",
       "3                k           0.000000             kg/m^2     3.090000   \n",
       "4                k           0.000000             kg/m^2    -4.810000   \n",
       "\n",
       "  wind_ew_unit wind_ns_data wind_ns_unit  \n",
       "0          m/s     2.540000          m/s  \n",
       "1          m/s     7.190000          m/s  \n",
       "2          m/s    -2.080000          m/s  \n",
       "3          m/s     6.350000          m/s  \n",
       "4          m/s     0.010000          m/s  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather shape : (10586016, 14)\n",
      "Minimum date :  2017-01-01  Maximum date :  2017-02-28\n",
      "Unique temperature data units :  ['k']  Unique precipitaion data units :  ['kg/m^2']\n"
     ]
    }
   ],
   "source": [
    "print('weather shape :',weather_df.shape)\n",
    "print('Minimum date : ',weather_df['date'].min(),' Maximum date : ',weather_df['date'].max())\n",
    "print('Unique temperature data units : ',weather_df['temperature_unit'].unique(),' Unique precipitaion data units : ',weather_df['precipitation_unit'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge drive and vehicle data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#localizing to CST timezone as this is the timezone at latitude and longitude from dataset\n",
    "drive_df['datetime'] = drive_df['datetime'].dt.tz_localize('US/Central')\n",
    "#Converting to PST time zone as required\n",
    "drive_df['datetime'] = drive_df['datetime'].dt.tz_convert('US/Pacific')\n",
    "all_data = pd.merge(drive_df,vehicle_df,on = 'vehicle_id',how = 'left').fillna(0)\n",
    "#del drive_df,vehicle_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with trip data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#localizing to CST timezone as this is the timezone at latitude and longitude from dataset\n",
    "trip_df['datetime'] = trip_df['datetime'].dt.tz_localize('US/Central')\n",
    "#Converting to PST time zone as required\n",
    "trip_df['datetime'] = trip_df['datetime'].dt.tz_convert('US/Pacific')\n",
    "all_data = pd.merge(all_data,trip_df,on = ['datetime','trip_id','vehicle_id'],how = 'left').fillna(0)\n",
    "#del trip_df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with weather data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geohash(lat,lon):\n",
    "    res = []\n",
    "    for i in range(len(lat)):\n",
    "        res.append(pgh.encode(lat[i], lon[i], precision=5))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df['time'] = pd.to_datetime(weather_df['time'],format = '%HZ')\n",
    "weather_df['time'] = weather_df['time'].dt.tz_localize('US/Pacific')\n",
    "\n",
    "#Chaning the temperature data to Fahrenheit as required\n",
    "weather_df['temperature_data'] = weather_df['temperature_data'].astype(np.float32)\n",
    "weather_df['temperature_data'] = weather_df['temperature_data']*(9/5) - 459.67\n",
    "weather_df['precipitation_data'] = weather_df['precipitation_data'].astype(np.float32)\n",
    "\n",
    "all_data['day'] = all_data['datetime'].dt.day\n",
    "all_data['month'] = all_data['datetime'].dt.month\n",
    "all_data['year'] = all_data['datetime'].dt.year\n",
    "all_data['hour'] = all_data['datetime'].dt.hour\n",
    "\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'],format = '%Y-%m-%d',errors='raise')\n",
    "weather_df['date'] = weather_df['date'].dt.tz_localize('US/Pacific')\n",
    "weather_df['day'] = weather_df['date'].dt.day\n",
    "weather_df['month'] = weather_df['date'].dt.month\n",
    "weather_df['year'] = weather_df['date'].dt.year\n",
    "weather_df['hour'] = weather_df['time'].dt.hour\n",
    "\n",
    "#Getting geohash value with precision 5 for weather data as well as combined data as this will be used for merging\n",
    "all_lats = all_data.lat.values\n",
    "all_longs = all_data.long.values\n",
    "\n",
    "all_data['geohash'] = geohash(all_lats,all_longs)\n",
    "\n",
    "weather_lats = weather_df.lat.values\n",
    "weather_lons = weather_df.lon.values\n",
    "\n",
    "weather_df['geohash'] = geohash(weather_lats,weather_lons)\n",
    "\n",
    "\n",
    "#Merging on hour,day,month,year as weather data is constant for complete hour\n",
    "all_data = pd.merge(all_data,weather_df,on = ['hour','day','month','year','geohash'],how = 'left').fillna(0)\n",
    "\n",
    "#del all_lats,all_longs,weather_lats,weather_lons,weather_df\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep only the columns required and downcast to reduce memory size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9217528 entries, 0 to 9217527\n",
      "Data columns (total 15 columns):\n",
      "vehicle_id            int32\n",
      "trip_id               object\n",
      "datetime              datetime64[ns, US/Pacific]\n",
      "eng_load              float32\n",
      "rpm                   float32\n",
      "max_torque            float32\n",
      "max_horsepower        float32\n",
      "max_horsepower_rpm    float32\n",
      "max_torque_rpm        float32\n",
      "lat_x                 float32\n",
      "long                  float32\n",
      "velocity_x            float32\n",
      "velocity_y            float32\n",
      "temperature_data      float32\n",
      "precipitation_data    float32\n",
      "dtypes: datetime64[ns, US/Pacific](1), float32(12), int32(1), object(1)\n",
      "memory usage: 1.3 GB\n"
     ]
    }
   ],
   "source": [
    "all_data = all_data[['vehicle_id','trip_id','datetime','eng_load','rpm','max_torque','max_horsepower',\n",
    "                     'max_horsepower_rpm','max_torque_rpm','lat_x','long','velocity_x','velocity_y','temperature_data','precipitation_data']]\n",
    "gc.collect()\n",
    "all_data = downcast_dtypes(all_data)\n",
    "all_data.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get week start date, torque utilization,active horsepower,horsepower utilization,rpm utilization,distance,time and acceleration fields which will be required in calculating required features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def torque_utilization(eng_load):\n",
    "    res = np.empty(eng_load.shape)\n",
    "    for i in range(len(eng_load)):\n",
    "        res[i] = eng_load[i]/255\n",
    "    return res\n",
    "\n",
    "@njit(parallel=True)\n",
    "def active_horsepower(eng_load,max_torque,rpm):\n",
    "    res = np.empty(eng_load.shape)\n",
    "    for i in range(len(eng_load)):\n",
    "        res[i] = (eng_load[i]/255)*max_torque[i]*(rpm[i]/5252)\n",
    "    return res\n",
    "\n",
    "@njit(parallel=True)\n",
    "def horsepower_utilization(max_horsepower,active_horsepower):\n",
    "    res = np.empty(max_horsepower.shape)\n",
    "    for i in range(len(max_horsepower)):\n",
    "        if max_horsepower[i] != 0:\n",
    "            res[i] = active_horsepower[i]/max_horsepower[i]\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return res\n",
    "\n",
    "@njit(parallel=True)\n",
    "def rpm_utilization(rpm,max_horsepower_rpm):\n",
    "    res = np.empty(rpm.shape)\n",
    "    for i in range(len(rpm)):\n",
    "        if max_horsepower_rpm[i] != 0:\n",
    "            res[i] = rpm[i]/max_horsepower_rpm[i]\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return res\n",
    "\n",
    "def distance(lat,lon):\n",
    "    res = np.empty(lat.shape)\n",
    "    res[0] = 0\n",
    "    for i in range(1,len(lat)):\n",
    "        res[i] = haversine((lat[i-1],lon[i-1]),(lat[i],lon[i]))\n",
    "    return res\n",
    "\n",
    "def calculate_time(datetime,datetime_min):\n",
    "    res = np.empty(datetime.shape)\n",
    "    res[0] = 0\n",
    "    for i in range(1,len(datetime)):\n",
    "        res[i] = (datetime[i]-datetime[i-1])/np.timedelta64(1,'s')\n",
    "        if datetime[i] == datetime_min[i]:\n",
    "            res[i] = 0\n",
    "    return res\n",
    "\n",
    "@njit(parallel=True)\n",
    "def acceleration(velocity_y,time):\n",
    "    res = np.empty(velocity_y.shape)\n",
    "    res[0] = 0\n",
    "    for i in range(1,len(velocity_y)):\n",
    "        if time[i] != 0:\n",
    "            res[i] = ((velocity_y[i] - velocity_y[i-1])*0.277778)/(time[i])\n",
    "        else:\n",
    "            res[i] = 0\n",
    "    return res\n",
    "\n",
    "@njit(parallel=True)\n",
    "def update_distance(datetime,datetime_min,distance):\n",
    "    res = np.empty(datetime.shape)\n",
    "    for i in range(len(datetime)):\n",
    "        if datetime[i] == datetime_min[i]:\n",
    "            res[i] = 0\n",
    "        else:\n",
    "            res[i] = distance[i]\n",
    "    return res\n",
    "\n",
    "@njit(parallel=True)\n",
    "def update_acceleration(datetime,datetime_min,acceleration):\n",
    "    res = np.empty(datetime.shape)\n",
    "    for i in range(len(datetime)):\n",
    "        if datetime[i] == datetime_min[i]:\n",
    "            res[i] = 0\n",
    "        else:\n",
    "            res[i] = acceleration[i]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['day_of_week'] = all_data.datetime.dt.weekday\n",
    "\n",
    "all_data['week_start_date'] = all_data.datetime - all_data.day_of_week * timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/generic.py:1315: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the min datetime for every veicle and trip as distance and acceleration should be set to 0 at this time\n",
    "# as well as week start day should be adjusted if min datetime is after monday for this week\n",
    "\n",
    "gb = all_data.groupby(['vehicle_id','trip_id'],as_index = False).agg({'datetime':{'datetime_min':'min'}})\n",
    "gb.columns = [col[0] if col[-1] == '' else col[-1] for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data,gb,on =['trip_id','vehicle_id'],how = 'left').fillna(0)\n",
    "del gb\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3296: FutureWarning: Converting timezone-aware DatetimeArray to timezone-naive ndarray with 'datetime64[ns]' dtype. In the future, this will return an ndarray with 'object' dtype where each element is a 'pandas.Timestamp' with the correct 'tz'.\n",
      "\tTo accept the future behavior, pass 'dtype=object'.\n",
      "\tTo keep the old behavior, pass 'dtype=\"datetime64[ns]\"'.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "all_data['week_start_date'] = np.where(all_data['datetime_min'] > all_data['week_start_date'],\n",
    "                                       all_data['datetime_min'],all_data['week_start_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['week_start_date'] = all_data.week_start_date.dt.date\n",
    "\n",
    "all_data = all_data.sort_values(['vehicle_id','trip_id','datetime'],ascending = [True,True,True])\n",
    "\n",
    "all_data['torque_utilization'] = torque_utilization(all_data['eng_load'].values)\n",
    "\n",
    "all_data['active_horsepower'] = active_horsepower(all_data['eng_load'].values,all_data['max_torque'].values,all_data['rpm'].values)\n",
    "\n",
    "all_data['horsepower_utilization'] = horsepower_utilization(all_data['max_horsepower'].values,all_data['active_horsepower'].values)\n",
    "\n",
    "all_data['rpm_utilization'] = rpm_utilization(all_data['rpm'].values,all_data['max_horsepower_rpm'].values)\n",
    "\n",
    "\n",
    "\n",
    "all_data['distance'] = distance(all_data['lat_x'].values,all_data['long'].values)\n",
    "\n",
    "all_data['time'] = calculate_time(all_data['datetime'].values,all_data['datetime_min'].values)\n",
    "\n",
    "all_data['acceleration'] = acceleration(all_data['velocity_y'].values,all_data['time'].values)\n",
    "\n",
    "all_data['distance'] = update_distance(all_data['datetime'].values,all_data['datetime_min'].values,all_data['distance'].values)\n",
    "\n",
    "all_data['acceleration'] = update_distance(all_data['datetime'].values,all_data['datetime_min'].values,all_data['acceleration'].values)\n",
    "\n",
    "all_data = downcast_dtypes(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get engine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine_features(group):\n",
    "    #print(type(group))\n",
    "    ft_torque_util_60pct_s = group.loc[(group['torque_utilization'] >= 0.6) & (group['torque_utilization'] < 0.7),'time'].sum()\n",
    "    ft_torque_util_70pct_s = group.loc[(group['torque_utilization'] >= 0.7) & (group['torque_utilization'] < 0.8),'time'].sum()\n",
    "    ft_torque_util_80pct_s = group.loc[(group['torque_utilization'] >= 0.8) & (group['torque_utilization'] < 0.9),'time'].sum()\n",
    "    ft_torque_util_90pct_s = group.loc[(group['torque_utilization'] >= 0.9),'time'].sum()\n",
    "    ft_horsepower_util_50pct_s = group.loc[(group['horsepower_utilization'] >= 0.5) & (group['horsepower_utilization'] < 0.6),\n",
    "                                           'time'].sum()\n",
    "    ft_horsepower_util_60pct_s = group.loc[(group['horsepower_utilization'] >= 0.6) & (group['horsepower_utilization'] < 0.7),\n",
    "                                           'time'].sum()\n",
    "    \n",
    "    ft_horsepower_util_70pct_s = group.loc[(group['horsepower_utilization'] >= 0.7) & (group['horsepower_utilization'] < 0.8),\n",
    "                                           'time'].sum()\n",
    "    \n",
    "    ft_torque_util_80pct_s = group.loc[(group['horsepower_utilization'] >= 0.8) & (group['horsepower_utilization'] < 0.9),\n",
    "                                           'time'].sum()\n",
    "    \n",
    "    ft_rpm_util_50pct_s = group.loc[(group['rpm_utilization'] >= 0.5) & (group['rpm_utilization'] < 0.6),\n",
    "                                           'time'].sum()\n",
    "    \n",
    "    ft_rpm_util_60pct_s = group.loc[(group['rpm_utilization'] >= 0.6) & (group['rpm_utilization'] < 0.7),\n",
    "                                           'time'].sum()\n",
    "    cols = ['ft_torque_util_60pct_s','ft_torque_util_70pct_s','ft_torque_util_80pct_s','ft_torque_util_90pct_s',\n",
    "            'ft_horsepower_util_50pct_s','ft_horsepower_util_60pct_s','ft_horsepower_util_70pct_s','ft_torque_util_80pct_s',\n",
    "            'ft_rpm_util_50pct_s','ft_rpm_util_60pct_s']\n",
    "    return pd.Series([ft_torque_util_60pct_s,ft_torque_util_70pct_s,ft_torque_util_80pct_s,ft_torque_util_90pct_s,\n",
    "            ft_horsepower_util_50pct_s,ft_horsepower_util_60pct_s,ft_horsepower_util_70pct_s,ft_torque_util_80pct_s,\n",
    "            ft_rpm_util_50pct_s,ft_rpm_util_60pct_s],index = cols)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6397"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine_features = all_data.groupby(['vehicle_id','week_start_date']).apply(get_engine_features).reset_index()\n",
    "engine_features.columns = ef.columns\n",
    "engine_features = engine_features.sort_values(['vehicle_id','week_start_date'],ascending = [True,True])\n",
    "#engine_features = round_floats(engine_features)\n",
    "engine_features.to_csv('engine_features.csv',index = False)\n",
    "#del engine_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# engine_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get drive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive_features = None\n",
    "temp = all_data.groupby(['trip_id'])\n",
    "values = []\n",
    "for name,group in temp:\n",
    "    #print(type(name))\n",
    "    #print(name)\n",
    "    ft_cnt_vehicle_deaccel_val = 0\n",
    "    ft_sum_time_accel_val = 0\n",
    "    ft_sum_time_deaccel_val = 0\n",
    "    ft_cnt_vehicle_accel_val = 0\n",
    "    ft_sum_hard_brakes_10_flg_val = 0\n",
    "    ft_sum_hard_brakes_3_flg_val = 0\n",
    "    ft_sum_hard_accel_10_flg_val = 0\n",
    "    ft_sum_hard_accel_3_flg_val = 0\n",
    "    min_accl = 0\n",
    "    max_accl = 0\n",
    "    first_index = None\n",
    "    #indexes = group.index.values\n",
    "    #print(indexes)\n",
    "    accelerations = group['acceleration'].values\n",
    "    times = group['time'].values\n",
    "    \n",
    "    for i in range(len(accelerations)):\n",
    "         \n",
    "        if accelerations[i] < 0:\n",
    "            \n",
    "            ft_sum_time_deaccel_val = ft_sum_time_deaccel_val + times[i]\n",
    "            \n",
    "            if i == 0:\n",
    "                ft_cnt_vehicle_deaccel_val = ft_cnt_vehicle_deaccel_val + 1\n",
    "                min_accl = accelerations[i]\n",
    "            elif accelerations[i-1] > 0:\n",
    "                ft_cnt_vehicle_deaccel_val = ft_cnt_vehicle_deaccel_val + 1\n",
    "                min_accl = accelerations[i]\n",
    "                \n",
    "            if (i+1) < len(accelerations) and accelerations[i + 1] > 0 :\n",
    "                min_accl = min(min_accl,accelerations[i])\n",
    "                if min_accl <= -10:\n",
    "                    ft_sum_hard_brakes_10_flg_val = ft_sum_hard_brakes_10_flg_val +1\n",
    "                if min_accl <= -3 and min_accl > -10:\n",
    "                    ft_sum_hard_brakes_3_flg_val = ft_sum_hard_brakes_3_flg_val + 1\n",
    "            elif (i+1) == len(accelerations):\n",
    "                min_accl = min(min_accl,accelerations[i])\n",
    "                if min_accl <= -10:\n",
    "                    ft_sum_hard_brakes_10_flg_val = ft_sum_hard_brakes_10_flg_val +1\n",
    "                if min_accl <= -3 and min_accl > -10:\n",
    "                    ft_sum_hard_brakes_3_flg_val = ft_sum_hard_brakes_3_flg_val + 1\n",
    "            else:\n",
    "                min_accl = min(min_accl,accelerations[i])\n",
    "\n",
    "        if accelerations[i] > 0:\n",
    "            ft_sum_time_accel_val = ft_sum_time_accel_val + times[i]\n",
    "            \n",
    "            if i == 0:\n",
    "                ft_cnt_vehicle_accel_val = ft_cnt_vehicle_accel_val + 1\n",
    "                max_accl = accelerations[i]\n",
    "            elif accelerations[i-1] < 0:\n",
    "                ft_cnt_vehicle_accel_val = ft_cnt_vehicle_accel_val + 1\n",
    "                max_accl = accelerations[i]\n",
    "                \n",
    "            if (i+1) < len(accelerations) and accelerations[i + 1] < 0 :\n",
    "                max_accl = max(max_accl,accelerations[i])\n",
    "                if max_accl >= 10:\n",
    "                    ft_sum_hard_accel_10_flg_val = ft_sum_hard_accel_10_flg_val +1\n",
    "                if max_accl >= 3 and max_accl < 10:\n",
    "                    ft_sum_hard_accel_3_flg_val = ft_sum_hard_accel_3_flg_val + 1\n",
    "            elif (i+1) == len(accelerations):\n",
    "                max_accl = max(max_accl,accelerations[i])\n",
    "                if max_accl >= 10:\n",
    "                    ft_sum_hard_accel_10_flg_val = ft_sum_hard_accel_10_flg_val +1\n",
    "                if max_accl >= 3 and max_accl < 10:\n",
    "                    ft_sum_hard_accel_3_flg_val = ft_sum_hard_accel_3_flg_val + 1\n",
    "            else:\n",
    "                max_accl = max(max_accl,accelerations[i])\n",
    "            \n",
    "\n",
    "    values.append(np.array([name,ft_cnt_vehicle_deaccel_val, ft_sum_time_accel_val,\n",
    "        ft_sum_time_deaccel_val, ft_cnt_vehicle_accel_val,\n",
    "       ft_sum_hard_brakes_10_flg_val, ft_sum_hard_brakes_3_flg_val,\n",
    "       ft_sum_hard_accel_10_flg_val, ft_sum_hard_accel_3_flg_val\n",
    "                      ]))\n",
    "    \n",
    "\n",
    "del accelerations,times,temp,group\n",
    "gc.collect()\n",
    "\n",
    "drive_features = pd.DataFrame(values,columns = df.columns)\n",
    "\n",
    "del values\n",
    "gc.collect()\n",
    "\n",
    "drive_features[['ft_cnt_vehicle_deaccel_val', 'ft_sum_hard_brakes_10_flg_val',\n",
    "       'ft_sum_hard_brakes_3_flg_val', 'ft_sum_time_deaccel_val','ft_cnt_vehicle_accel_val',\n",
    "        'ft_sum_hard_accel_10_flg_val','ft_sum_hard_accel_3_flg_val','ft_sum_time_accel_val']] = drive_features[[\n",
    "    'ft_cnt_vehicle_deaccel_val', 'ft_sum_hard_brakes_10_flg_val',\n",
    "       'ft_sum_hard_brakes_3_flg_val', 'ft_sum_time_deaccel_val','ft_cnt_vehicle_accel_val',\n",
    "        'ft_sum_hard_accel_10_flg_val','ft_sum_hard_accel_3_flg_val','ft_sum_time_accel_val']].astype(np.float32)\n",
    "\n",
    "drive_features = drive_features[['trip_id','ft_cnt_vehicle_deaccel_val', 'ft_sum_hard_brakes_10_flg_val',\n",
    "       'ft_sum_hard_brakes_3_flg_val', 'ft_sum_time_deaccel_val','ft_cnt_vehicle_accel_val',\n",
    "        'ft_sum_hard_accel_10_flg_val','ft_sum_hard_accel_3_flg_val','ft_sum_time_accel_val']]\n",
    "\n",
    "#drive_features = drive_features.drop(drive_features[drive_features.sum(axis = 1) == 0].index)\n",
    "#drive_features = round_floats(drive_features)\n",
    "drive_features = drive_features.sort_values(['trip_id'],ascending = [True])\n",
    "drive_features.to_csv('drive_features.csv',index = False)\n",
    "#del drive_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1708, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drive_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_features(group):\n",
    "    total_light_rain_driving_km = group.loc[(group['precipitation_data'] > 0) & (group['precipitation_data'] <= 2.5) & (group['temperature_data'] > 32),'distance'].sum()\n",
    "    total_light_freezing_rain_driving_km = group.loc[(group['precipitation_data'] > 0) & (group['precipitation_data'] <= 2.5) & (group['temperature_data'] > 27)  \n",
    "                                                     & (group['temperature_data'] <= 32),'distance'].sum()\n",
    "    total_light_snow_driving_km = group.loc[(group['precipitation_data'] > 0) & (group['precipitation_data'] <= 2.5) & (group['temperature_data'] <= 27),'distance'].sum()\n",
    "    total_moderate_rain_driving_km = group.loc[(group['precipitation_data'] > 2.5) & (group['precipitation_data'] <= 7.6) & (group['temperature_data'] > 32),'distance'].sum()\n",
    "    total_moderate_freezing_rain_driving_km = group.loc[(group['precipitation_data'] > 2.5) & (group['precipitation_data'] <= 7.6) & (group['temperature_data'] > 27)  \n",
    "                                                     & (group['temperature_data'] <= 32),'distance'].sum()\n",
    "    total_moderate_snow_driving_km = group.loc[(group['precipitation_data'] > 2.5) & (group['precipitation_data'] <= 7.6) & (group['temperature_data'] <= 27),'distance'].sum()\n",
    "    total_heavy_rain_driving_km = group.loc[(group['precipitation_data'] > 7.6) & (group['temperature_data'] > 32) ,'distance'].sum()\n",
    "    cols = ['total_light_rain_driving_km','total_light_freezing_rain_driving_km', 'total_light_snow_driving_km','total_moderate_rain_driving_km',\n",
    "            'total_moderate_freezing_rain_driving_km','total_moderate_snow_driving_km', 'total_heavy_rain_driving_km']\n",
    "    return pd.Series([total_light_rain_driving_km,total_light_freezing_rain_driving_km, total_light_snow_driving_km,total_moderate_rain_driving_km,total_moderate_freezing_rain_driving_km,\n",
    "       total_moderate_snow_driving_km, total_heavy_rain_driving_km],index = cols)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_features = all_data.groupby(['vehicle_id','week_start_date']).apply(get_weather_features).reset_index()\n",
    "weather_features.columns = wf.columns\n",
    "weather_features = weather_features.sort_values(['vehicle_id','week_start_date'],ascending = [True,True])\n",
    "#weather_features = round_floats(weather_features)\n",
    "weather_features.to_csv('weather_features.csv',index = False)\n",
    "#del weather_features,all_data,df,ef,wf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weather_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time elapsed 821.786804 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "print('total time elapsed %f seconds'%(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
